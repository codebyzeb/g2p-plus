{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "Brief bit of code for converting the database info into a README or latex table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zebulongoriely/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "config_file = '../childes_processor/phonemizer_config.json'\n",
    "childes_folder = '../CHILDES-dataset'\n",
    "\n",
    "collection_map = {\n",
    "    'basque' : 'Other/Basque',\n",
    "    'dutch' : 'DutchAfricaans/Dutch',\n",
    "    'englishNA' : 'Eng-NA',\n",
    "    'englishUK' : 'Eng-UK',\n",
    "    'indonesian' : 'EastAsian/Indonesian',\n",
    "    'mandarin' : 'Chinese/Mandarin',\n",
    "    'serbian' : 'Slavic/Serbian',\n",
    "    'estonian' : 'Other/Estonian',\n",
    "    'cantonese' : 'Chinese/Cantonese',\n",
    "    'polish' : 'Slavic/Polish',\n",
    "    'swedish' : 'Scandinavian/Swedish',\n",
    "    'portuguesept' : 'Romance/Portuguese',\n",
    "    'portuguesebr' : 'Romance/Portuguese',\n",
    "    'korean' : 'EastAsian/Korean',\n",
    "    'italian' : 'Romance/Italian',\n",
    "    'catalan' : 'Romance/Catalan',\n",
    "    'croatian' : 'Slavic/Croatian',\n",
    "    'welsh' : 'Celtic/Welsh',\n",
    "    'icelandic' : 'Scandinavian/Icelandic',\n",
    "    'danish' : 'Scandinavian/Danish',\n",
    "    'norwegian' : 'Scandinavian/Norwegian',\n",
    "    'hungarian' : 'Other/Hungarian',\n",
    "    'romaninian' : 'Other/Romanian',\n",
    "    'irish' : 'Celtic/Irish',\n",
    "    'turkish' : 'Other/Turkish',\n",
    "    'quechua' : 'Other/Quechua',\n",
    "    'farsi' : 'Other/Farsi',\n",
    "}\n",
    "\n",
    "PHONEME_SETS = {\n",
    "    'basque' : 2161,\n",
    "    'cantonese' : 2309,\n",
    "    'catalan' : 2555,\n",
    "    'croatian' : 1139,\n",
    "    'danish' : 2265,\n",
    "    'dutch' : 2405,\n",
    "    'englishna' : 2175,\n",
    "    'englishuk' : 2252,\n",
    "    'estonian' : 2181,\n",
    "    'farsi' : 516,\n",
    "    'french' : 2269,\n",
    "    'german' : 2398,\n",
    "    'hungarian' : 2191,\n",
    "    'icelandic' : 2568,\n",
    "    'indonesian' : 1690,\n",
    "    'italian' : 1145,\n",
    "    'irish' : 2521,\n",
    "    'japanese' : 2196,\n",
    "    'korean' : 423,\n",
    "    'mandarin' : 2457,\n",
    "    'norwegian' : 499,\n",
    "    'polish' : 1046,\n",
    "    'romanian' : 2443,\n",
    "    'serbian' : 2499,\n",
    "    'spanish' : 164,\n",
    "    'swedish' : 1150,\n",
    "    'portuguesept' : 2206,\n",
    "    'portuguesebr' : 2207,\n",
    "    'quechua' : 104,\n",
    "    'turkish' : 2217,\n",
    "    'welsh' : 2406,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/6tzh0bsj2txd1cz18gpcms_c0000gn/T/ipykernel_51036/2075820410.py:1: DtypeWarning: Columns (4,7,8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  phoible = pd.read_csv('../../../data/phoible.csv')\n"
     ]
    }
   ],
   "source": [
    "phoible = pd.read_csv('../../../data/phoible.csv')\n",
    "phonemes = phoible.Phoneme.unique()\n",
    "TONES = '˧˥˩̰˨˩˦'\n",
    "\n",
    "def get_phoneme_set(lines):\n",
    "    token_counts = {}\n",
    "    for line in lines:\n",
    "        # Our tool combines tone markers with the preceeding vowel, we remove tone markers in our comparison so that we don't get many \"unknown phonemes\" consisting of a known vowel + tone marker.\n",
    "        #line = line.replace('˧˥', '').replace('˧˩̰', '').replace('˩˧', '').replace('˨', '').replace('˥', '').replace('˧', '').replace('˧˥', '').replace('˧˩̰', '').replace('˩˧','').replace('˩','').replace('˦','')\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            if token == 'WORD_BOUNDARY':\n",
    "                continue\n",
    "            if token not in token_counts:\n",
    "                token_counts[token] = 0\n",
    "            token_counts[token] += 1\n",
    "    vowels = []\n",
    "    consonants = []\n",
    "    other = []\n",
    "    for phoneme in token_counts:\n",
    "        cmp_phoneme = phoneme\n",
    "        if phoneme not in phonemes:\n",
    "            has_tones = False\n",
    "            for tone in TONES:\n",
    "                if tone in phoneme:\n",
    "                    has_tones = True\n",
    "                    cmp_phoneme = cmp_phoneme.replace(tone, '')\n",
    "            if not has_tones or cmp_phoneme not in phonemes:\n",
    "                print(f'{phoneme} not in phoible')\n",
    "                other.append(phoneme)\n",
    "                continue\n",
    "        if phoible[phoible.Phoneme == cmp_phoneme].SegmentClass.iloc[0] == 'vowel':\n",
    "            vowels.append(phoneme)\n",
    "        elif phoible[phoible.Phoneme == cmp_phoneme].SegmentClass.iloc[0] == 'consonant':\n",
    "            consonants.append(phoneme)\n",
    "        else:\n",
    "            other.append(phoneme)\n",
    "\n",
    "    return vowels, consonants, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polish...\n",
      "z̻ʲ not in phoible\n",
      "\n",
      "Serbian...\n",
      "ä̈ not in phoible\n",
      "\n",
      "Romanian...\n",
      "\n",
      "PortugueseBr...\n",
      "\n",
      "PortuguesePt...\n",
      "\n",
      "Italian...\n",
      "\n",
      "Catalan...\n",
      "\n",
      "Quechua...\n",
      "\n",
      "Norwegian...\n",
      "\n",
      "Swedish...\n",
      "\n",
      "Korean...\n",
      "\n",
      "Welsh...\n",
      "ɪuː not in phoible\n",
      "\n",
      "Irish...\n",
      "\n",
      "Indonesian...\n",
      "\n",
      "Icelandic...\n",
      "\n",
      "Farsi...\n",
      "\n",
      "Turkish...\n",
      "\n",
      "Hungarian...\n",
      "\n",
      "Basque...\n",
      "\n",
      "Danish...\n",
      "\n",
      "Croatian...\n",
      "\n",
      "Estonian...\n",
      "\n",
      "Cantonese...\n",
      "\n",
      "Japanese...\n",
      "\n",
      "Mandarin...\n",
      "\n",
      "Dutch...\n",
      "\n",
      "Spanish...\n",
      "î not in phoible\n",
      "k̈ not in phoible\n",
      "ê̞ not in phoible\n",
      "\n",
      "German...\n",
      "oː̈ not in phoible\n",
      "uː̂ not in phoible\n",
      "A not in phoible\n",
      "Ø not in phoible\n",
      "Z not in phoible\n",
      "I not in phoible\n",
      "\n",
      "French...\n",
      "\n",
      "EnglishUK...\n",
      "\n",
      "English...\n"
     ]
    }
   ],
   "source": [
    "columns = ['Language', 'CHILDES Collection', 'Backend', 'Language Code', 'Inventory ID', 'Description',\n",
    "           'Speakers', 'Utterances', 'Words', 'Phonemes',\n",
    "           '% Child', 'Phoneme Types', 'Consonants', 'Vowels']\n",
    "\n",
    "data = {column: [] for column in columns}\n",
    "\n",
    "# load json config\n",
    "config = json.load(open(config_file))\n",
    "\n",
    "for config_name in datasets.get_dataset_config_names(childes_folder)[::-1]:\n",
    "    print('\\n' + config_name + '...')\n",
    "    \n",
    "    dataset = datasets.load_dataset('../CHILDES-dataset', config_name)\n",
    "    dataset = datasets.concatenate_datasets([dataset['train'], dataset['valid']])\n",
    "\n",
    "    config_name = 'EnglishNA' if config_name == 'English' else config_name\n",
    "    language = config_name\n",
    "    config_name = config_name.lower()\n",
    "\n",
    "    collection = collection_map[config_name] if config_name in collection_map else language\n",
    "    backend = config[config_name]['backend']\n",
    "    lang_code = config[config_name]['language']\n",
    "    inventory_id = PHONEME_SETS[config_name]\n",
    "    num_corpora = len(set(dataset['corpus_id']))\n",
    "    speakers = len(set(dataset['speaker_id']))\n",
    "    total_utterances = len(dataset)\n",
    "    total_words = sum([utterance.count('WORD_BOUNDARY') for utterance in list(dataset['phonemized_utterance'])])\n",
    "    total_phonemes = sum([len(utterance.split()) for utterance in dataset['phonemized_utterance']]) - total_words\n",
    "    percentage_child = 100 * len([c for c in dataset['is_child'] if c]) / total_utterances\n",
    "    vowels, consonants, other = get_phoneme_set(dataset['phonemized_utterance'])\n",
    "    n_phonemes = len(set(vowels + consonants + other))\n",
    "    description = f\"Taken from {num_corpora} corpora in the {collection} collection of CHILDES and phonemized using `{backend}` with language code `{lang_code}`.\"\n",
    "\n",
    "    data['Language'].append(language)\n",
    "    data['CHILDES Collection'].append(collection)\n",
    "    data['Backend'].append(backend)\n",
    "    data['Language Code'].append(lang_code)\n",
    "    data['Inventory ID'].append(inventory_id)\n",
    "    data['Description'].append(description)\n",
    "    data['Speakers'].append(speakers)\n",
    "    data['Utterances'].append(total_utterances)\n",
    "    data['Words'].append(total_words)\n",
    "    data['Phonemes'].append(total_phonemes)\n",
    "    data['% Child'].append(percentage_child)\n",
    "    data['Phoneme Types'].append(n_phonemes)\n",
    "    data['Consonants'].append(len(consonants))\n",
    "    data['Vowels'].append(len(vowels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readme_table(columns):\n",
    "    text = \" | \".join(columns) + \"\\n\"\n",
    "    text += \"|:----\" * len(columns) + \"|\"\n",
    "\n",
    "    # Sort data by number of utterances\n",
    "    languages = [x for _, x in sorted(zip(data['Phonemes'], data['Language']))][::-1]\n",
    "\n",
    "    for language in languages:\n",
    "        idx = data['Language'].index(language)\n",
    "        text += \"\\n\"\n",
    "        for column in columns:\n",
    "            if isinstance(data[column][idx], int):\n",
    "                text += f\"| {data[column][idx]:,}\"\n",
    "            elif isinstance(data[column][idx], float):\n",
    "                text += f\"| {data[column][idx]:.2f}\"\n",
    "            else:\n",
    "                text += f\"| {data[column][idx]}\"\n",
    "            #text += f\"| {data[column][idx]}\"\n",
    "        #text += f\"\\n| {data['Language'][idx]} | {data['Description'][idx]} | {data['Speakers'][idx]} | {data['Total Utterances'][idx]:,} | {data['Total Words'][idx]:,} | {data['Total Phonemes'][idx]:,} |\"\n",
    "        # Number of phonemes with comma between thousands\n",
    "    return text\n",
    "\n",
    "def create_latex_table():\n",
    "    text = \"\"\"| Language | Description | Speakers | Utterances | Words | Phonemes\n",
    "|:----|:-----|:-----|:----|:-----|:-----|\"\"\"\n",
    "\n",
    "    # Sort data by number of utterances\n",
    "    languages = [x for _, x in sorted(zip(data['Total Phonemes'], data['Language']))][::-1]\n",
    "\n",
    "    for language in languages:\n",
    "        idx = data['Language'].index(language)\n",
    "        text += f\"\\n| {data['Language'][idx]} | {data['Description'][idx]} | {data['Speakers'][idx]} | {data['Total Utterances'][idx]:,} | {data['Total Words'][idx]:,} | {data['Total Phonemes'][idx]:,} |\"\n",
    "        # Number of phonemes with comma between thousands\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language | Description | Speakers | Utterances | Words | Phonemes | % Child\n",
      "|:----|:----|:----|:----|:----|:----|:----|\n",
      "| EnglishNA| Taken from 49 corpora in the EnglishNA collection of CHILDES and phonemized using `phonemizer` with language code `en-us`.| 3,687| 2,564,614| 9,993,744| 30,986,218| 35.83\n",
      "| EnglishUK| Taken from 16 corpora in the EnglishUK collection of CHILDES and phonemized using `phonemizer` with language code `en-gb`.| 869| 2,043,115| 7,147,541| 21,589,844| 39.00\n",
      "| German| Taken from 10 corpora in the German collection of CHILDES and phonemized using `epitran` with language code `deu-Latn`.| 829| 1,525,559| 5,825,166| 21,442,576| 43.61\n",
      "| Japanese| Taken from 11 corpora in the Japanese collection of CHILDES and phonemized using `phonemizer` with language code `ja`.| 489| 998,642| 2,970,674| 11,985,729| 44.20\n",
      "| Indonesian| Taken from 1 corpora in the EastAsian/Indonesian collection of CHILDES and phonemized using `epitran` with language code `ind-Latn`.| 438| 813,795| 2,347,642| 9,370,983| 34.32\n",
      "| French| Taken from 15 corpora in the French collection of CHILDES and phonemized using `phonemizer` with language code `fr-fr`.| 1,277| 721,121| 2,973,318| 8,203,649| 40.07\n",
      "| Spanish| Taken from 18 corpora in the Spanish collection of CHILDES and phonemized using `epitran` with language code `spa-Latn`.| 1,009| 533,308| 2,183,992| 7,742,550| 45.93\n",
      "| Mandarin| Taken from 16 corpora in the Chinese/Mandarin collection of CHILDES and phonemized using `pinyin_to_ipa` with language code `mandarin`.| 2,118| 530,342| 2,264,518| 6,605,913| 38.89\n",
      "| Dutch| Taken from 5 corpora in the DutchAfricaans/Dutch collection of CHILDES and phonemized using `phonemizer` with language code `nl`.| 107| 403,472| 1,475,174| 4,786,803| 35.08\n",
      "| Polish| Taken from 2 corpora in the Slavic/Polish collection of CHILDES and phonemized using `phonemizer` with language code `pl`.| 511| 218,860| 1,042,841| 4,361,797| 63.26\n",
      "| Serbian| Taken from 1 corpora in the Slavic/Serbian collection of CHILDES and phonemized using `epitran` with language code `srp-Latn`.| 208| 319,305| 1,052,337| 3,841,600| 29.14\n",
      "| Estonian| Taken from 9 corpora in the Other/Estonian collection of CHILDES and phonemized using `phonemizer` with language code `et`.| 157| 186,921| 843,189| 3,429,228| 44.71\n",
      "| Welsh| Taken from 2 corpora in the Celtic/Welsh collection of CHILDES and phonemized using `phonemizer` with language code `cy`.| 269| 181,292| 666,350| 1,939,286| 69.18\n",
      "| Cantonese| Taken from 2 corpora in the Chinese/Cantonese collection of CHILDES and phonemized using `pingyam` with language code `cantonese`.| 95| 205,729| 777,997| 1,864,771| 33.54\n",
      "| Swedish| Taken from 3 corpora in the Scandinavian/Swedish collection of CHILDES and phonemized using `phonemizer` with language code `sv`.| 41| 154,064| 581,451| 1,782,692| 44.63\n",
      "| PortuguesePt| Taken from 4 corpora in the Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt`.| 45| 134,543| 499,522| 1,538,408| 39.47\n",
      "| Korean| Taken from 3 corpora in the EastAsian/Korean collection of CHILDES and phonemized using `phonemizer` with language code `ko`.| 127| 105,281| 263,030| 1,345,276| 36.76\n",
      "| Italian| Taken from 5 corpora in the Romance/Italian collection of CHILDES and phonemized using `phonemizer` with language code `it`.| 109| 94,361| 352,861| 1,309,489| 39.02\n",
      "| Croatian| Taken from 1 corpora in the Slavic/Croatian collection of CHILDES and phonemized using `epitran` with language code `hrv-Latn`.| 54| 90,992| 305,112| 1,109,696| 39.24\n",
      "| Catalan| Taken from 6 corpora in the Romance/Catalan collection of CHILDES and phonemized using `phonemizer` with language code `ca`.| 180| 89,103| 319,726| 1,084,594| 36.49\n",
      "| Icelandic| Taken from 2 corpora in the Scandinavian/Icelandic collection of CHILDES and phonemized using `phonemizer` with language code `is`.| 17| 78,181| 279,939| 1,057,235| 35.21\n",
      "| Basque| Taken from 2 corpora in the Other/Basque collection of CHILDES and phonemized using `phonemizer` with language code `eu`.| 286| 71,537| 230,500| 942,725| 48.82\n",
      "| Hungarian| Taken from 3 corpora in the Other/Hungarian collection of CHILDES and phonemized using `epitran` with language code `hun-Latn`.| 116| 69,690| 237,062| 918,002| 47.95\n",
      "| Danish| Taken from 1 corpora in the Scandinavian/Danish collection of CHILDES and phonemized using `phonemizer` with language code `da`.| 29| 84,019| 275,170| 824,314| 41.71\n",
      "| Norwegian| Taken from 2 corpora in the Scandinavian/Norwegian collection of CHILDES and phonemized using `phonemizer` with language code `nb`.| 34| 61,906| 227,856| 729,649| 42.58\n",
      "| PortugueseBr| Taken from 2 corpora in the Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt-br`.| 331| 22,439| 174,845| 577,865| 44.42\n",
      "| Romanian| Taken from 3 corpora in the Romanian collection of CHILDES and phonemized using `phonemizer` with language code `ro`.| 33| 54,982| 152,465| 537,669| 42.62\n",
      "| Turkish| Taken from 2 corpora in the Other/Turkish collection of CHILDES and phonemized using `phonemizer` with language code `tr`.| 118| 29,317| 79,404| 421,129| 50.58\n",
      "| Irish| Taken from 2 corpora in the Celtic/Irish collection of CHILDES and phonemized using `phonemizer` with language code `ga`.| 29| 27,818| 105,867| 338,425| 34.37\n",
      "| Quechua| Taken from 2 corpora in the Other/Quechua collection of CHILDES and phonemized using `phonemizer` with language code `qu`.| 14| 22,397| 46,848| 281,478| 40.06\n",
      "| Farsi| Taken from 2 corpora in the Other/Farsi collection of CHILDES and phonemized using `phonemizer` with language code `fa-latn`.| 29| 22,613| 43,432| 178,523| 40.45\n"
     ]
    }
   ],
   "source": [
    "print(create_readme_table(['Language', 'Description', 'Speakers', 'Utterances', 'Words', 'Phonemes', '% Child']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m new_lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage & CHILDES Collection & Backend & Language Code & Speakers & Utterances & Words & Phonemes + \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m      2\u001b[0m summ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m:]:\n\u001b[1;32m      4\u001b[0m     line_data \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     new_lines\u001b[38;5;241m.\u001b[39mappend(line_data[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m & \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "new_lines = ['Language & CHILDES Collection & Backend & Language Code & Speakers & Utterances & Words & Phonemes + \\\\\\\\']  \n",
    "summ = 0\n",
    "for line in text.split('\\n')[2:]:\n",
    "    line_data = line.split('| ')\n",
    "    new_lines.append(line_data[1] + ' & ')\n",
    "    # find text between \"in\" and \"collection\" using regex\n",
    "    collection = re.search(r'in (.*) collection', line_data[2]).group(1)\n",
    "    corpora = re.search(r'from (.*) corp', line_data[2]).group(1)\n",
    "    backend = re.search(r'using `(.*)` with', line_data[2]).group(1)\n",
    "    language_code = re.search(r'code `(.*)`', line_data[2]).group(1)\n",
    "\n",
    "    new_lines[-1] += collection + ' (' + corpora + ') & ' + backend + ' & ' + language_code + ' & ' + line_data[3] + ' & ' + line_data[4] + ' & ' + line_data[5] + ' & ' + line_data[6] + ' \\\\\\\\'\n",
    "    summ += int(line_data[4].replace(',', ''))\n",
    "print('\\n'.join(new_lines) + '\\n')\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6325870419446221,\n",
       " 0.2913797153192089,\n",
       " 0.42617583936561054,\n",
       " 0.44422656981148895,\n",
       " 0.39466192964331104,\n",
       " 0.3901929822702176,\n",
       " 0.3649147615680729,\n",
       " 0.40058936464705097,\n",
       " 0.42579071495493165,\n",
       " 0.44634048187766123,\n",
       " 0.3676351858360008,\n",
       " 0.6918176201928381,\n",
       " 0.34373427277302465,\n",
       " 0.34316996295135754,\n",
       " 0.352054847085609,\n",
       " 0.40445761287754833,\n",
       " 0.5058498482109356,\n",
       " 0.4795236045343665,\n",
       " 0.48818094133105944,\n",
       " 0.4170842309477618,\n",
       " 0.3923861438368208,\n",
       " 0.44713007099255836,\n",
       " 0.3354023983006771,\n",
       " 0.44202727303678396,\n",
       " 0.3889395899249918,\n",
       " 0.3507901415711623,\n",
       " 0.45927681564874334,\n",
       " 0.436077529613735,\n",
       " 0.40074827941496644,\n",
       " 0.3900436343524471,\n",
       " 0.35826717003026576]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['% Child']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
