{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex Table\n",
    "\n",
    "Brief bit of code for converting the database info into a latex table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zebulongoriely/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "config_file = '../childes_processor/phonemizer_config.json'\n",
    "childes_folder = '../CHILDES-dataset'\n",
    "\n",
    "collection_map = {\n",
    "    'basque' : 'Other/Basque',\n",
    "    'dutch' : 'DutchAfricaans/Dutch',\n",
    "    'englishNA' : 'Eng-NA',\n",
    "    'englishUK' : 'Eng-UK',\n",
    "    'indonesian' : 'EastAsian/Indonesian',\n",
    "    'mandarin' : 'Chinese/Mandarin',\n",
    "    'serbian' : 'Slavic/Serbian',\n",
    "    'estonian' : 'Other/Estonian',\n",
    "    'cantonese' : 'Chinese/Cantonese',\n",
    "    'polish' : 'Slavic/Polish',\n",
    "    'swedish' : 'Scandinavian/Swedish',\n",
    "    'portuguesept' : 'Romance/Portuguese',\n",
    "    'portuguesebr' : 'Romance/Portuguese',\n",
    "    'korean' : 'EastAsian/Korean',\n",
    "    'italian' : 'Romance/Italian',\n",
    "    'catalan' : 'Romance/Catalan',\n",
    "    'croatian' : 'Slavic/Croatian',\n",
    "    'welsh' : 'Celtic/Welsh',\n",
    "    'icelandic' : 'Scandinavian/Icelandic',\n",
    "    'danish' : 'Scandinavian/Danish',\n",
    "    'norwegian' : 'Scandinavian/Norwegian',\n",
    "    'hungarian' : 'Other/Hungarian',\n",
    "    'romaninian' : 'Other/Romanian',\n",
    "    'irish' : 'Celtic/Irish',\n",
    "    'turkish' : 'Other/Turkish',\n",
    "    'quechua' : 'Other/Quechua',\n",
    "    'farsi' : 'Other/Farsi',\n",
    "}\n",
    "\n",
    "PHONEME_SETS = {\n",
    "    'basque' : 2161,\n",
    "    'cantonese' : 2309,\n",
    "    'catalan' : 2555,\n",
    "    'croatian' : 1139,\n",
    "    'danish' : 2265,\n",
    "    'dutch' : 2405,\n",
    "    'englishna' : 2175,\n",
    "    'englishuk' : 2252,\n",
    "    'estonian' : 2181,\n",
    "    'farsi' : 516,\n",
    "    'french' : 2269,\n",
    "    'german' : 2398,\n",
    "    'hungarian' : 2191,\n",
    "    'icelandic' : 2568,\n",
    "    'indonesian' : 1690,\n",
    "    'italian' : 1145,\n",
    "    'irish' : 2521,\n",
    "    'japanese' : 2196,\n",
    "    'korean' : 423,\n",
    "    'mandarin' : 2457,\n",
    "    'norwegian' : 499,\n",
    "    'polish' : 1046,\n",
    "    'romanian' : 2443,\n",
    "    'serbian' : 2499,\n",
    "    'spanish' : 164,\n",
    "    'swedish' : 1150,\n",
    "    'portuguesept' : 2206,\n",
    "    'portuguesebr' : 2207,\n",
    "    'quechua' : 104,\n",
    "    'turkish' : 2217,\n",
    "    'welsh' : 2406,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/6tzh0bsj2txd1cz18gpcms_c0000gn/T/ipykernel_84166/2075820410.py:1: DtypeWarning: Columns (4,7,8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  phoible = pd.read_csv('../../../data/phoible.csv')\n"
     ]
    }
   ],
   "source": [
    "phoible = pd.read_csv('../../../data/phoible.csv')\n",
    "phonemes = phoible.Phoneme.unique()\n",
    "TONES = '˧˥˩̰˨˩˦'\n",
    "\n",
    "def get_phoneme_set(lines):\n",
    "    token_counts = {}\n",
    "    for line in lines:\n",
    "        # Our tool combines tone markers with the preceeding vowel, we remove tone markers in our comparison so that we don't get many \"unknown phonemes\" consisting of a known vowel + tone marker.\n",
    "        #line = line.replace('˧˥', '').replace('˧˩̰', '').replace('˩˧', '').replace('˨', '').replace('˥', '').replace('˧', '').replace('˧˥', '').replace('˧˩̰', '').replace('˩˧','').replace('˩','').replace('˦','')\n",
    "        tokens = line.strip().split()\n",
    "        for token in tokens:\n",
    "            if token == 'WORD_BOUNDARY':\n",
    "                continue\n",
    "            if token not in token_counts:\n",
    "                token_counts[token] = 0\n",
    "            token_counts[token] += 1\n",
    "    vowels = []\n",
    "    consonants = []\n",
    "    other = []\n",
    "    for phoneme in token_counts:\n",
    "        cmp_phoneme = phoneme\n",
    "        if phoneme not in phonemes:\n",
    "            has_tones = False\n",
    "            for tone in TONES:\n",
    "                if tone in phoneme:\n",
    "                    has_tones = True\n",
    "                    cmp_phoneme = cmp_phoneme.replace(tone, '')\n",
    "            if not has_tones or cmp_phoneme not in phonemes:\n",
    "                print(f'{phoneme} not in phoible')\n",
    "                other.append(phoneme)\n",
    "                continue\n",
    "        if phoible[phoible.Phoneme == cmp_phoneme].SegmentClass.iloc[0] == 'vowel':\n",
    "            vowels.append(phoneme)\n",
    "        elif phoible[phoible.Phoneme == cmp_phoneme].SegmentClass.iloc[0] == 'consonant':\n",
    "            consonants.append(phoneme)\n",
    "        else:\n",
    "            other.append(phoneme)\n",
    "\n",
    "    return vowels, consonants, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish...\n",
      "\n",
      "Serbian...\n",
      "\n",
      "́ not in phoible\n",
      "Romanian...\n",
      "\n",
      "PortugueseBr...\n",
      "\n",
      "PortuguesePt...\n",
      "\n",
      "Italian...\n",
      "\n",
      "Catalan...\n",
      "\n",
      "Quechua...\n",
      "\n",
      "Norwegian...\n",
      "\n",
      "Swedish...\n",
      "\n",
      "Korean...\n",
      "\n",
      "Welsh...\n",
      "\n",
      "Irish...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config_name \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mget_dataset_config_names(childes_folder)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(config_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../CHILDES-dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mconcatenate_datasets([dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     16\u001b[0m     config_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglishNA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m config_name\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/load.py:2582\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2579\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2582\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2591\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2592\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2593\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2594\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/builder.py:1005\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/builder.py:1100\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m-> 1100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1107\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/builder.py:1860\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1858\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[0;32m-> 1860\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single(\n\u001b[1;32m   1861\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs, job_id\u001b[38;5;241m=\u001b[39mjob_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_split_args\n\u001b[1;32m   1862\u001b[0m     ):\n\u001b[1;32m   1863\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   1864\u001b[0m             result \u001b[38;5;241m=\u001b[39m content\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/builder.py:1989\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     writer \u001b[38;5;241m=\u001b[39m writer_class(\n\u001b[1;32m   1982\u001b[0m         features\u001b[38;5;241m=\u001b[39mwriter\u001b[38;5;241m.\u001b[39m_features,\n\u001b[1;32m   1983\u001b[0m         path\u001b[38;5;241m=\u001b[39mfpath\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSSSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshard_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJJJJJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1986\u001b[0m         embed_local_files\u001b[38;5;241m=\u001b[39membed_local_files,\n\u001b[1;32m   1987\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1989\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationCastError\u001b[38;5;241m.\u001b[39mfrom_cast_error(\n\u001b[1;32m   1992\u001b[0m         cast_error\u001b[38;5;241m=\u001b[39mcast_error,\n\u001b[1;32m   1993\u001b[0m         builder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mbuilder_name,\n\u001b[1;32m   1994\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs,\n\u001b[1;32m   1995\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m   1996\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/datasets/arrow_writer.py:589\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[0;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 589\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/pyarrow/ipc.pxi:529\u001b[0m, in \u001b[0;36mpyarrow.lib._CRecordBatchWriter.write_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/pyarrow/error.pxi:89\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/UniDocs/PHD/research/projects/CorpusPhonemizers/env/lib/python3.10/site-packages/fsspec/implementations/local.py:373\u001b[0m, in \u001b[0;36mLocalFileOpener.write\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = ['Language', 'CHILDES Collection', 'Backend', 'Language Code', 'Inventory ID', 'Description',\n",
    "           'Speakers', 'Total Utterances', 'Total Words', 'Total Phonemes',\n",
    "           '% Child', 'Phonemes', 'Consonants', 'Vowels']\n",
    "\n",
    "data = {column: [] for column in columns}\n",
    "\n",
    "# load json config\n",
    "config = json.load(open(config_file))\n",
    "\n",
    "for config_name in datasets.get_dataset_config_names(childes_folder)[::-1]:\n",
    "    print('\\n' + config_name + '...')\n",
    "    \n",
    "    dataset = datasets.load_dataset('../CHILDES-dataset', config_name)\n",
    "    dataset = datasets.concatenate_datasets([dataset['train'], dataset['valid']])\n",
    "\n",
    "    config_name = 'EnglishNA' if config_name == 'English' else config_name\n",
    "    language = config_name\n",
    "    config_name = config_name.lower()\n",
    "\n",
    "    collection = collection_map[config_name] if config_name in collection_map else language\n",
    "    backend = config[config_name]['backend']\n",
    "    lang_code = config[config_name]['language']\n",
    "    inventory_id = PHONEME_SETS[config_name]\n",
    "    num_corpora = len(set(dataset['corpus_id']))\n",
    "    speakers = len(set(dataset['speaker_id']))\n",
    "    total_utterances = len(dataset)\n",
    "    total_words = sum([utterance.count('WORD_BOUNDARY') for utterance in list(dataset['phonemized_utterance'])])\n",
    "    total_phonemes = sum([len(utterance.split()) for utterance in dataset['phonemized_utterance']]) - total_words\n",
    "    percentage_child = len([c for c in dataset['is_child'] if c]) / total_utterances\n",
    "    vowels, consonants, other = get_phoneme_set(dataset['phonemized_utterance'])\n",
    "    n_phonemes = len(set(vowels + consonants + other))\n",
    "    description = f\"Taken from {num_corpora} corpora in the {collection} collection of CHILDES and phonemized using `{backend}` with language code `{lang_code}`.\"\n",
    "\n",
    "    data['Language'].append(language)\n",
    "    data['CHILDES Collection'].append(collection)\n",
    "    data['Backend'].append(backend)\n",
    "    data['Language Code'].append(lang_code)\n",
    "    data['Inventory ID'].append(inventory_id)\n",
    "    data['Description'].append(description)\n",
    "    data['Speakers'].append(speakers)\n",
    "    data['Total Utterances'].append(total_utterances)\n",
    "    data['Total Words'].append(total_words)\n",
    "    data['Total Phonemes'].append(total_phonemes)\n",
    "    data['% Child'].append(percentage_child)\n",
    "    data['Phonemes'].append(n_phonemes)\n",
    "    data['Consonants'].append(len(consonants))\n",
    "    data['Vowels'].append(len(vowels))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language & CHILDES Collection & Backend & Language Code & Speakers & Utterances & Words & Phonemes + \\\\\n",
      "English (US)  & Eng-NA (44) & phonemizer & en-us & 2,692  & 1,645,797  & 7,096,724  & 22,107,530 \\\\\n",
      "English (UK)  & Eng-NA (14) & phonemizer & en-gb & 588  & 1,246,211  & 5,170,088  & 15,710,282 \\\\\n",
      "German  & German (10) & epitran & deu-Latn & 628  & 860,297  & 3,967,699  & 14,821,724 \\\\\n",
      "Japanese  & Japanese (9) & phonemizer & japanese & 329  & 557,215  & 1,773,816  & 7,100,307 \\\\\n",
      "Indonesian  & EastAsian/Indonesian (1) & epitran & ind-Latn & 389  & 534,525  & 2,122,372  & 6,369,459 \\\\\n",
      "French  & French (11) & phonemizer & fr-fr & 722  & 432,133  & 1,995,063  & 5,510,523 \\\\\n",
      "Spanish  & Spanish (18) & epitran & spa-Latn & 562  & 288,372  & 1,567,124  & 4,553,108 \\\\\n",
      "Mandarin  & Chinese/Mandarin (15) & pinyin_to_ipa & mandarin & 883  & 324,071  & 1,506,475  & 4,397,546 \\\\\n",
      "Dutch  & DutchAfricaans/Dutch (4) & phonemizer & nl & 78  & 261,938  & 1,106,865  & 3,585,608 \\\\\n",
      "Serbian  & Slavic/Serbian (1) & epitran & srp-Latn & 199  & 226,266  & 1,054,074  & 3,067,398 \\\\\n",
      "Estonian  & Other/Estonian (9) & phonemizer & et & 118  & 103,343  & 544,680  & 2,226,518 \\\\\n",
      "Polish  & Slavic/Polish (2) & phonemizer & pl & 466  & 80,412  & 381,940  & 1,599,152 \\\\\n",
      "Cantonese  & Chinese/Cantonese (2) & pingyam & cantonese & 80  & 136,727  & 591,314  & 1,425,686 \\\\\n",
      "Swedish  & Scandinavian/Swedish (3) & phonemizer & sv & 32  & 85,299  & 396,800  & 1,242,615 \\\\\n",
      "Portuguese (Portugal)  & Romance/Portuguese (3) & phonemizer & pt & 33  & 81,444  & 368,032  & 1,117,010 \\\\\n",
      "Korean  & EastAsian/Korean (3) & phonemizer & ko & 95  & 66,576  & 201,078  & 1,074,044 \\\\\n",
      "Italian  & Romance/Italian (5) & phonemizer & it & 92  & 57,542  & 264,479  & 996,701 \\\\\n",
      "Catalan  & Romance/Catalan (5) & phonemizer & ca & 159  & 56,588  & 248,999  & 839,462 \\\\\n",
      "Croatian  & Slavic/Croatian (1) & phonemizer & hr & 51  & 55,288  & 214,949  & 805,530 \\\\\n",
      "Welsh  & Celtic/Welsh (2) & phonemizer & cy & 65  & 55,871  & 269,295  & 785,569 \\\\\n",
      "Icelandic  & Scandinavian/Icelandic (2) & phonemizer & is & 15  & 50,657  & 197,519  & 751,804 \\\\\n",
      "Danish  & Scandinavian/Danish (1) & phonemizer & da & 25  & 48,976  & 192,527  & 579,972 \\\\\n",
      "Norwegian  & Scandinavian/Norwegian (2) & phonemizer & nb & 27  & 35,547  & 175,952  & 559,340 \\\\\n",
      "Basque  & Other/Basque (2) & phonemizer & eu & 150  & 36,614  & 135,866  & 565,633 \\\\\n",
      "Hungarian  & Other/Hungarian (3) & epitran & hun-Latn & 65  & 36,272  & 147,334  & 588,934 \\\\\n",
      "Romanian  & Romance/Romanian (2) & phonemizer & ro & 21  & 31,550  & 110,067  & 380,577 \\\\\n",
      "Portuguese (Brazil)  & Romance/Portuguese (2) & phonemizer & pt-br & 163  & 12,471  & 91,484  & 303,998 \\\\\n",
      "Irish  & Celtic/Irish (2) & phonemizer & ga & 20  & 18,256  & 88,388  & 278,558 \\\\\n",
      "Turkish  & Other/Turkish (2) & phonemizer & tr & 35  & 14,487  & 43,823  & 230,737 \\\\\n",
      "Quechua  & Other/Quechua (2) & phonemizer & qu & 7  & 13,425  & 33,102  & 204,692 \\\\\n",
      "Farsi  & Other/Farsi (2) & phonemizer & fa-latn & 23  & 13,467  & 28,080  & 115,089 \\\\\n",
      "\n",
      "7467637\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"| Language | Description | Speakers | Utterances | Words | Phonemes\n",
    "|:----|:-----|:-----|:----|:-----|:-----|\n",
    "| English (US) | Taken from 44 corpora in Eng-NA collection of CHILDES and phonemized using `phonemizer` with language code `en-us`. | 2,692 | 1,645,797 | 7,096,724 | 22,107,530\n",
    "| English (UK) | Taken from 14 corpora in Eng-NA collection of CHILDES and phonemized using `phonemizer` with language code `en-gb`. | 588 | 1,246,211 | 5,170,088 | 15,710,282\n",
    "| German | Taken from 10 corpora in German collection of CHILDES and phonemized using `epitran` with language code `deu-Latn`. | 628 | 860,297 | 3,967,699 | 14,821,724\n",
    "| Japanese | Taken from 9 corpora in Japanese collection of CHILDES and phonemized using `phonemizer` with language code `japanese`. | 329 | 557,215 | 1,773,816 | 7,100,307\n",
    "| Indonesian | Taken from 1 corpus in EastAsian/Indonesian collection of CHILDES and phonemized using `epitran` with language code `ind-Latn`. | 389 | 534,525 | 2,122,372 | 6,369,459\n",
    "| French | Taken from 11 corpora in French collection of CHILDES and phonemized using `phonemizer` with language code `fr-fr`. | 722 | 432,133 | 1,995,063 | 5,510,523\n",
    "| Spanish | Taken from 18 corpora in Spanish collection of CHILDES and phonemized using `epitran` with language code `spa-Latn`. | 562 | 288,372 | 1,567,124 | 4,553,108\n",
    "| Mandarin | Taken from 15 corpora in Chinese/Mandarin collection of CHILDES and phonemized using `pinyin_to_ipa` with language code `mandarin`. | 883 | 324,071 | 1,506,475 | 4,397,546\n",
    "| Dutch | Taken from 4 corpora in DutchAfricaans/Dutch collection of CHILDES and phonemized using `phonemizer` with language code `nl`. | 78 | 261,938 | 1,106,865 | 3,585,608\n",
    "| Serbian | Taken from 1 corpus in Slavic/Serbian collection of CHILDES and phonemized using `epitran` with language code `srp-Latn`. | 199 | 226,266 | 1,054,074 | 3,067,398\n",
    "| Estonian | Taken from 9 corpora in Other/Estonian collection of CHILDES and phonemized using `phonemizer` with language code `et`. | 118 | 103,343 | 544,680 | 2,226,518\n",
    "| Polish | Taken from 2 corpora in Slavic/Polish collection of CHILDES and phonemized using `phonemizer` with language code `pl`. | 466 | 80,412 | 381,940 | 1,599,152\n",
    "| Cantonese | Taken from 2 corpora in Chinese/Cantonese collection of CHILDES and phonemized using `pingyam` with language code `cantonese`. | 80 | 136,727 | 591,314 | 1,425,686\n",
    "| Swedish | Taken from 3 corpora in Scandinavian/Swedish collection of CHILDES and phonemized using `phonemizer` with language code `sv`. | 32 | 85,299 | 396,800 | 1,242,615\n",
    "| Portuguese (Portugal) | Taken from 3 corpora in Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt`. | 33 | 81,444 | 368,032 | 1,117,010\n",
    "| Korean | Taken from 3 corpora in EastAsian/Korean collection of CHILDES and phonemized using `phonemizer` with language code `ko`. | 95 | 66,576 | 201,078 | 1,074,044\n",
    "| Italian | Taken from 5 corpora in Romance/Italian collection of CHILDES and phonemized using `phonemizer` with language code `it`. | 92 | 57,542 | 264,479 | 996,701\n",
    "| Catalan | Taken from 5 corpora in Romance/Catalan collection of CHILDES and phonemized using `phonemizer` with language code `ca`. | 159 | 56,588 | 248,999 | 839,462\n",
    "| Croatian | Taken from 1 corpus in Slavic/Croatian collection of CHILDES and phonemized using `phonemizer` with language code `hr`. | 51 | 55,288 | 214,949 | 805,530\n",
    "| Welsh | Taken from 2 corpora in Celtic/Welsh collection of CHILDES and phonemized using `phonemizer` with language code `cy`. | 65 | 55,871 | 269,295 | 785,569\n",
    "| Icelandic | Taken from 2 corpora in Scandinavian/Icelandic collection of CHILDES and phonemized using `phonemizer` with language code `is`. | 15 | 50,657 | 197,519 | 751,804\n",
    "| Danish | Taken from 1 corpus in Scandinavian/Danish collection of CHILDES and phonemized using `phonemizer` with language code `da`. | 25 | 48,976 | 192,527 | 579,972\n",
    "| Norwegian | Taken from 2 corpora in Scandinavian/Norwegian collection of CHILDES and phonemized using `phonemizer` with language code `nb`. | 27 | 35,547 | 175,952 | 559,340\n",
    "| Basque | Taken from 2 corpora in Other/Basque collection of CHILDES and phonemized using `phonemizer` with language code `eu`. | 150 | 36,614 | 135,866 | 565,633\n",
    "| Hungarian | Taken from 3 corpora in Other/Hungarian collection of CHILDES and phonemized using `epitran` with language code `hun-Latn`. | 65 | 36,272 | 147,334 | 588,934\n",
    "| Romanian | Taken from 2 corpora in Romance/Romanian collection of CHILDES and phonemized using `phonemizer` with language code `ro`. | 21 | 31,550 | 110,067 | 380,577\n",
    "| Portuguese (Brazil) | Taken from 2 corpora in Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt-br`. | 163 | 12,471 | 91,484 | 303,998\n",
    "| Irish | Taken from 2 corpora in Celtic/Irish collection of CHILDES and phonemized using `phonemizer` with language code `ga`. | 20 | 18,256 | 88,388 | 278,558\n",
    "| Turkish | Taken from 2 corpora in Other/Turkish collection of CHILDES and phonemized using `phonemizer` with language code `tr`. | 35 | 14,487 | 43,823 | 230,737\n",
    "| Quechua | Taken from 2 corpora in Other/Quechua collection of CHILDES and phonemized using `phonemizer` with language code `qu`. | 7 | 13,425 | 33,102 | 204,692\n",
    "| Farsi | Taken from 2 corpora in Other/Farsi collection of CHILDES and phonemized using `phonemizer` with language code `fa-latn`. | 23 | 13,467 | 28,080 | 115,089\"\"\"\n",
    "\n",
    "new_lines = ['Language & CHILDES Collection & Backend & Language Code & Speakers & Utterances & Words & Phonemes + \\\\\\\\']  \n",
    "summ = 0\n",
    "for line in text.split('\\n')[2:]:\n",
    "    line_data = line.split('| ')\n",
    "    new_lines.append(line_data[1] + ' & ')\n",
    "    # find text between \"in\" and \"collection\" using regex\n",
    "    collection = re.search(r'in (.*) collection', line_data[2]).group(1)\n",
    "    corpora = re.search(r'from (.*) corp', line_data[2]).group(1)\n",
    "    backend = re.search(r'using `(.*)` with', line_data[2]).group(1)\n",
    "    language_code = re.search(r'code `(.*)`', line_data[2]).group(1)\n",
    "\n",
    "    new_lines[-1] += collection + ' (' + corpora + ') & ' + backend + ' & ' + language_code + ' & ' + line_data[3] + ' & ' + line_data[4] + ' & ' + line_data[5] + ' & ' + line_data[6] + ' \\\\\\\\'\n",
    "    summ += int(line_data[4].replace(',', ''))\n",
    "print('\\n'.join(new_lines) + '\\n')\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readme_table():\n",
    "    text = \"\"\"| Language | Description | Speakers | Utterances | Words | Phonemes\n",
    "|:----|:-----|:-----|:----|:-----|:-----|\"\"\"\n",
    "\n",
    "    # Sort data by number of utterances\n",
    "    languages = [x for _, x in sorted(zip(data['Total Utterances'], data['Language']))][::-1]\n",
    "\n",
    "    for language in languages:\n",
    "        idx = data['Language'].index(language)\n",
    "        text += f\"\\n| {data['Language'][idx]} | {data['Description'][idx]} | {data['Speakers'][idx]} | {data['Total Utterances'][idx]} | {data['Total Words'][idx]} | {data['Total Phonemes'][idx]} |\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Language | Description | Speakers | Utterances | Words | Phonemes\n",
      "|:----|:-----|:-----|:----|:-----|:-----|\n",
      "| EnglishNA | Taken from 44 corpora in the EnglishNA collection of CHILDES and phonemized using `phonemizer` with language code `en-us`. | 2692 | 1645797 | 7096724 | 22107530 |\n",
      "| EnglishUK | Taken from 14 corpora in the EnglishUK collection of CHILDES and phonemized using `phonemizer` with language code `en-gb`. | 588 | 1246211 | 5170088 | 15710282 |\n",
      "| German | Taken from 10 corpora in the German collection of CHILDES and phonemized using `epitran` with language code `deu-Latn`. | 628 | 860297 | 3967699 | 14821812 |\n",
      "| Japanese | Taken from 9 corpora in the Japanese collection of CHILDES and phonemized using `epitran` with language code `ja`. | 329 | 557215 | 1773816 | 7100307 |\n",
      "| Indonesian | Taken from 1 corpora in the EastAsian/Indonesian collection of CHILDES and phonemized using `epitran` with language code `ind-Latn`. | 389 | 534525 | 1587847 | 6369459 |\n",
      "| French | Taken from 11 corpora in the French collection of CHILDES and phonemized using `phonemizer` with language code `fr-fr`. | 722 | 432133 | 1995063 | 5510523 |\n",
      "| Mandarin | Taken from 15 corpora in the Chinese/Mandarin collection of CHILDES and phonemized using `pinyin_to_ipa` with language code `mandarin`. | 883 | 330902 | 1882579 | 4670334 |\n",
      "| Spanish | Taken from 18 corpora in the Spanish collection of CHILDES and phonemized using `epitran` with language code `spa-Latn`. | 562 | 288372 | 1278748 | 4553108 |\n",
      "| Dutch | Taken from 4 corpora in the DutchAfricaans/Dutch collection of CHILDES and phonemized using `phonemizer` with language code `nl`. | 78 | 261938 | 1106865 | 3585608 |\n",
      "| Serbian | Taken from 1 corpora in the Slavic/Serbian collection of CHILDES and phonemized using `epitran` with language code `srp-Latn`. | 199 | 226266 | 827808 | 3067398 |\n",
      "| Cantonese | Taken from 2 corpora in the Chinese/Cantonese collection of CHILDES and phonemized using `pingyam` with language code `cantonese`. | 81 | 147673 | 651392 | 1824730 |\n",
      "| Estonian | Taken from 9 corpora in the Other/Estonian collection of CHILDES and phonemized using `phonemizer` with language code `et`. | 118 | 103343 | 544680 | 2226518 |\n",
      "| Swedish | Taken from 3 corpora in the Scandinavian/Swedish collection of CHILDES and phonemized using `phonemizer` with language code `sv`. | 32 | 85299 | 396800 | 1242615 |\n",
      "| PortuguesePt | Taken from 3 corpora in the Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt`. | 33 | 81444 | 368032 | 1117010 |\n",
      "| Polish | Taken from 2 corpora in the Slavic/Polish collection of CHILDES and phonemized using `phonemizer` with language code `pl`. | 466 | 80412 | 381940 | 1599152 |\n",
      "| Korean | Taken from 3 corpora in the EastAsian/Korean collection of CHILDES and phonemized using `phonemizer` with language code `ko`. | 95 | 66576 | 201078 | 1074044 |\n",
      "| Italian | Taken from 5 corpora in the Romance/Italian collection of CHILDES and phonemized using `phonemizer` with language code `it`. | 92 | 57542 | 264479 | 996701 |\n",
      "| Catalan | Taken from 5 corpora in the Romance/Catalan collection of CHILDES and phonemized using `phonemizer` with language code `ca`. | 159 | 56588 | 248999 | 839462 |\n",
      "| Welsh | Taken from 2 corpora in the Celtic/Welsh collection of CHILDES and phonemized using `phonemizer` with language code `cy`. | 65 | 55871 | 269295 | 785569 |\n",
      "| Croatian | Taken from 1 corpora in the Slavic/Croatian collection of CHILDES and phonemized using `epitran` with language code `hrv-Latn`. | 51 | 55288 | 214949 | 805530 |\n",
      "| Icelandic | Taken from 2 corpora in the Scandinavian/Icelandic collection of CHILDES and phonemized using `phonemizer` with language code `is`. | 15 | 50657 | 197519 | 751804 |\n",
      "| Danish | Taken from 1 corpora in the Scandinavian/Danish collection of CHILDES and phonemized using `phonemizer` with language code `da`. | 25 | 48976 | 192527 | 579972 |\n",
      "| Basque | Taken from 2 corpora in the Other/Basque collection of CHILDES and phonemized using `phonemizer` with language code `eu`. | 150 | 36614 | 135866 | 565633 |\n",
      "| Hungarian | Taken from 3 corpora in the Other/Hungarian collection of CHILDES and phonemized using `epitran` with language code `hun-Latn`. | 65 | 36272 | 147334 | 588934 |\n",
      "| Norwegian | Taken from 2 corpora in the Scandinavian/Norwegian collection of CHILDES and phonemized using `phonemizer` with language code `nb`. | 27 | 35547 | 175952 | 559340 |\n",
      "| Romanian | Taken from 2 corpora in the Romanian collection of CHILDES and phonemized using `phonemizer` with language code `ro`. | 21 | 31550 | 110067 | 380577 |\n",
      "| Irish | Taken from 2 corpora in the Celtic/Irish collection of CHILDES and phonemized using `phonemizer` with language code `ga`. | 20 | 18256 | 88388 | 278558 |\n",
      "| Turkish | Taken from 2 corpora in the Other/Turkish collection of CHILDES and phonemized using `phonemizer` with language code `tr`. | 81 | 14487 | 43823 | 230737 |\n",
      "| Farsi | Taken from 2 corpora in the Other/Farsi collection of CHILDES and phonemized using `phonemizer` with language code `fa-latn`. | 23 | 13467 | 28080 | 115089 |\n",
      "| Quechua | Taken from 2 corpora in the Other/Quechua collection of CHILDES and phonemized using `phonemizer` with language code `qu`. | 7 | 13425 | 33102 | 204692 |\n",
      "| PortugueseBr | Taken from 2 corpora in the Romance/Portuguese collection of CHILDES and phonemized using `phonemizer` with language code `pt-br`. | 163 | 12471 | 91484 | 303998 |\n"
     ]
    }
   ],
   "source": [
    "print(create_readme_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
